# -*- coding: utf-8 -*-
"""Movie_Recommendation_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10IrZwRT1gfhzC9l43_PKuB6Q8ZmP0C4H

# Proyek System Rekomendasi : Movie Recommendation

- Nama: Usamah Putra Firdaus
- Email: usamahfirdaa@gmail.com
- ID Dicoding: Usamah Putra Firdaus
"""

!pip install kaggle

"""# **Import Library**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# **Data Load**"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d nicoletacilibiu/movies-and-ratings-for-recommendation-system
!unzip movies-and-ratings-for-recommendation-system.zip

movies_df = pd.read_csv('movies.csv')
movies_df.head()

ratings_df = pd.read_csv('ratings.csv')
ratings_df.head()

"""# **Data Understanding**

## **Data Basic Information**
"""

movies_df.info()

movies_df.shape

ratings_df.info()

ratings_df.shape

n_ratings = len(ratings_df)
n_movies = len(ratings_df['movieId'].unique())
n_users = len(ratings_df['userId'].unique())

print(f"Jumlah Data Rating: {n_ratings}")
print(f"Jumlah Data Movie: {n_movies}")
print(f"Jumlah Data User: {n_users}")
print(f"Rata-rata Rating per User: {round(n_ratings/n_users, 2)}")
print(f"Rara-rata Rating per Movie: {round(n_ratings/n_movies,2)}")

"""Dari hasil analisis, terdapat total 100.836 data rating yang diberikan oleh 610 user terhadap 9.724 film. Setiap user memberikan rata-rata sekitar 165 rating, menunjukkan bahwa user dalam dataset ini tergolong aktif. Namun, setiap film hanya menerima rata-rata sekitar 10 rating, yang mengindikasikan kemungkinan adanya ketimpangan distribusi rating antar film, beberapa film mungkin sangat populer sementara banyak lainnya hanya menerima sedikit rating. Hal ini dapat memengaruhi performa sistem rekomendasi, terutama dalam menghadapi masalah cold start untuk film dengan sedikit rating.

# **Data Preparation**

## **Data Cleaning**

### **Movies**
"""

movies_df

"""Memisahkan tahun dalam judul film, dan membuat kolom baru `year_of_release`"""

movies_df['year_of_release'] = movies_df.title.str.extract('(\(\d\d\d\d\))', expand=False)
movies_df.head()

"""kode diatas memisahkan tahun dalam judul. Akan dicari tahun (4 digit angka) yang berada di dalam tanda kurung ( ). Tujuannya agar tidak salah menangkap angka lain di dalam judul (misalnya angka dalam "2001: A Space Odyssey")."""

movies_df['year_of_release'] = movies_df.year_of_release.str.extract('(\d\d\d\d)',expand=False)
movies_df.head(3)

"""Setelah menghapus tanda `()` pada kolom `year_of_release`, selanjutnya menghapus tahun pada kolom `title`"""

movies_df['title'] = movies_df['title'].str.replace('(\(\d\d\d\d\))', '', regex=True)
movies_df.head()

"""### **Ratings**"""

ratings_df

# Dropping the timestamp column
ratings_df.drop('timestamp', axis=1, inplace=True)

# Confirming the drop
ratings_df.head(3)

"""Karena pada proyek ini tidak memerlukan timestamp, jadi kolom tersebut dihapus

## **Data Merging**
"""

# merge dataframe
films = pd.merge(movies_df, ratings_df, on='movieId', how='left')
films

"""Disini saya menggabungkan dataframe `movies_df` dengan dataframe `ratings_df` menggunakan `left join`

### Data Cleaning

memeriksa nilai yang kosong dan membersihkannya
"""

# check missing values
(films.isnull() | films.empty | films.isna()).sum()

"""Karena hanya sedikit yang terdapat nilai kosong, sehingga nilai yang kosong dihapus"""

# handling missing values
films = films.dropna()
films

# recheck missing values
(films.isnull() | films.empty | films.isna()).sum()

all_genres = set()
films['genres'].str.split('|').apply(all_genres.update)

print('Jumlah genre unik:', len(all_genres))
print('Daftar genre unik:', all_genres)

"""setelah dilihat genres yang unik, terdapat genre yang `(no genres listed)` selanjutnya akan dilakukan breakdown terlebih dahulu"""

# Menampilkan film dengan genre '(no genres listed)'
no_genre_movies = films[films['genres'] == '(no genres listed)']

# Menampilkan hasil
print('Jumlah film dengan genre (no genres listed):', len(no_genre_movies))
no_genre_movies

"""Dapat kita lihat terdapat 37 film yang tidak memiliki genre, jadi film yang tidak memiliki genre akan dihapus karena tidak digunakan dalam tahap modeling"""

films = films[films['genres'] != '(no genres listed)']

all_genres = set()
films['genres'].str.split('|').apply(all_genres.update)

print('Jumlah genre unik:', len(all_genres))
print('Daftar genre unik:', all_genres)

films.loc[:, 'genres'] = films['genres'].str.lower().str.replace('|', ' ', regex=False)

"""Selanjutnya, mari kita pisahkan nilai-nilai pada kolom genres menjadi `(' ')` agar lebih mudah untuk dibaca

### **Membuat 2 Variable Dataframe Berbeda**

Karena tujuan kita membuat modeling dengan 2 metode yang berbeda yaitu `Content Based Filtering` dan `Collaborative Filtering`. Maka treatment setiap dataset akan berbeda
"""

content_df = films.copy()
content_df

collab_df = films.copy()
collab_df

"""### Handling Data untuk Content Based Filtering

Karena datafrane digunakan untuk metode Content Based Filtering sehingga nama film yang sama perlu dihapus terlebih dahulu
"""

# duplicated by movieId
content_df.duplicated('movieId').sum()

# duplicated by title
content_df.duplicated('title').sum()

# drop duplicated data by movieId & title
content_df = films.drop_duplicates('movieId')
content_df = films.drop_duplicates('title')

content_df

# Bersihkan spasi di kolom
content_df.loc[:, 'title'] = content_df['title'].str.strip()
content_df.loc[:, 'genres'] = content_df['genres'].str.strip()

"""Kode diatas digunakan untuk menghapus spasi diakhir nama judul pada kolom `title` dan `genres` untuk Dataframe Content Based Filtering

#### **TF-IDF Vektorisasi**
"""

data = content_df
data.sample(5)

"""proses term frequency-inverse document frequency (TF-IDF) untuk mencari kata yang penting dalam kolom genre. setelah melakukan perhitungan idf akan didapatkan index. kemudian, saya akan mencoba melakukan mapping untuk menampilkan data genre-nya."""

# Misal films sudah ada
data = content_df.copy()

# Lanjutkan proses TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(token_pattern=r"(?u)\b[\w-]+\b")
tfidf_matrix = tfidf.fit_transform(data['genres'])

print("Fitur TF-IDF:", tfidf.get_feature_names_out())

tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())
print(tfidf_df.head())

tfidf_matrix = tfidf.fit_transform(data['genres'])

tfidf_matrix.shape

"""didapatkan ukuran matrix (9409, 19). dimana terdapat 9409 jumlah data dan 19 genre films. karena hasil 'tfidf' masih berbentuk vektor maka akan saya ubah ke dalam bentuk matrix."""

# change tf-idf vector to matrix form
tfidf_matrix.todense()

"""selanjutnya melihat hasil matriks tf-idf untuk beberapa sample film"""

df_tfidf = pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(),
    index=data.title
)

# Cek ukuran baris dan kolom
num_rows, num_cols = df_tfidf.shape

# Ambil sampel yang aman
sampled_df = df_tfidf.sample(min(10, num_rows), axis=0).sample(min(20, num_cols), axis=1)

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(),
    index=data.title
).sample(19, axis=1).sample(10, axis=0)

"""Hasil diatas menunjukkan representasi dari feature yang penting dari setiap genres film

### Handling Data untuk Collaborative Filtering
"""

collab_df.loc[:, 'title'] = collab_df['title'].str.strip()

"""Kode diatas digunakan untuk menghapus spasi diakhir nama judul pada kolom `title` untuk dataframe Collaborative Filtering"""

collab_df = collab_df.pivot_table(index="userId", columns="title", values="rating")
collab_df

"""Karena dilihat dari Exploratory Data, setiap film hanya menerima rata-rata sekitar 10 rating dari user, jadi kita asumsikan banyak film yang hanya di rating 1-5 oleh user yang membuat rata-rata rating cukup rendah, sehingga kita abaikan saja film-film yang dirating <5 user. Serta dilihat banyak nilai NaN pada hasil diatas, dimana maksud NaN adalah user tersebut belum merating film tersebut, sehingga kita isi dengan nilai 0 untuk merepresentasikan film tersebut belum dirating oleh user tersebut"""

collab_df = collab_df.dropna(thresh=5, axis=1).fillna(0)
collab_df

"""# **Modeling**

## **Content Based Filtering**

### **Cosine Similarity**

Menghitung similarity antar film yang satu dengan film lainnya berdasarkan genre
"""

# calculate cosine similarity on matrix
from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""menampilkan similarity matrix setiap film dengan menampilkan nama film dalam baris dan kolom."""

# create dataframe from the results of cosine similarity
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['title'], columns=data['title'])
print('Shape:', cosine_sim_df.shape)

# show similarity matrix
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### **Get Recommendation**

membuat function untuk merekomendasikan film dengan memberikan top 5 rekomendasi film.
"""

# function recommendations
def film_recommendations(title, similarity_data=cosine_sim_df, items=data[['title', 'genres']], k=5):
    # get data index
    index = similarity_data.loc[:,title].to_numpy().argpartition(
        range(-1, -k, -1))

    # retrieve data from an existing index
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # drop title you want to search
    closest = closest.drop(title, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

# sample data
data.sample(3)

"""pada data sample diatas menampilkan judul film `Saving Christmas`. Saya akan mencoba memberikan rekomendasi jika user telah menonton film tersebut"""

data[data.title.eq('Saving Christmas')]

film_recommendations('Saving Christmas')

"""Hasil diatas menunjukkan top 5 rekomendasi film untuk user yang telah menonton `Saving Christmas`

### Evaluation

Tahap terakhir adalah melihat performa metode Content Based Filtering
"""

def evaluate_recommendations(title, k=5):
    # Ambil rekomendasi
    recommended = film_recommendations(title, k=k)

    # Ambil genre dari film utama
    main_genres = set(data.loc[data['title'] == title, 'genres'].iloc[0].split(', '))

    results = []
    for rec_title in recommended['title']:
        rec_genres = set(data.loc[data['title'] == rec_title, 'genres'].iloc[0].split(', '))
        common_genres = main_genres.intersection(rec_genres)
        similarity_score = len(common_genres) / len(main_genres) if main_genres else 0
        results.append({
            'Recommended Title': rec_title,
            'Common Genres': common_genres,
            'Genre Similarity': round(similarity_score, 2)
        })

    return pd.DataFrame(results)

evaluate_recommendations('Saving Christmas', k=5)

"""Dari hasil Evaluasi menunjukkan bahwa Metode Content Based Filtering dapat memberikan rekomendasi yang akurat dengan nilai similarity 1

## **Collaborative Filtering**
"""

from scipy import sparse
from sklearn.metrics.pairwise import cosine_similarity

"""### **Cosine Similarity**

Mengukur kesamaan antar item (misalnya film) menggunakan Cosine Similarity berdasarkan perilaku pengguna (user-item interaction matrix)
"""

def standardize(row):
    return (row - row.mean()) / (row.max() - row.min())

data_std = collab_df.apply(standardize)
item_similarity = cosine_similarity(data_std.T)
item_similarity = pd.DataFrame(item_similarity, index=collab_df.columns, columns=collab_df.columns)
item_similarity

"""Membuat Fungsi untuk mendapatkan skor kesamaan setiap film berdasarkan nama film dan rating pengguna yang diberikan"""

def get_similar_movies(movie_name, user_rating):
    if movie_name not in item_similarity:
        print(f"Not Found: {movie_name}")
        return
    similar_score = item_similarity[movie_name] * (user_rating-2.5)  # manipulate the similar score using given rating by user
    similar_score = pd.DataFrame(similar_score).T
    return np.array(similar_score).reshape(-1)

print(get_similar_movies("Zodiac", 3.5))

"""### **Membuat User Profile**

Melihat 10 sample film
"""

# ambil 10 judul film acak tanpa menampilkan userId/rating
sample_titles = collab_df.columns.to_series().sample(10).tolist()

sample_titles

"""Dari 10 sample diatas digunakan untuk membuat user profile, yang akan digunakan untuk mendemokan sistem rekomendasi menggunakan metode Collaborative Filtering"""

usamah_profile = [
    ("Zodiac", 3.5),
    ("Muse, The", 2.0),
    ("Rambo: First Blood Part II", 2.5),
    ("Doc Hollywood", 4.5),
    ("Erin Brockovich", 5.0),
    ("Fantasia", 3.0),
    ("Fun with Dick and Jane", 4.5),
    ("Brothers", 5.0),
    ("Indecent Proposal", 4.0)
]

"""### **Mendapatkan Rekomendasi Berdasarkan User Profile**"""

similar_movies = pd.DataFrame(columns=collab_df.columns)

for i, (movie, rating) in enumerate(usamah_profile):
    sim_scores = get_similar_movies(movie, rating)
    similar_movies.loc[i] = sim_scores

# Profil user (film yang sudah ditonton)
watched_movies = [movie for movie, rating in usamah_profile]
recommendation_scores = similar_movies.sum().sort_values(ascending=False)
recommendation_scores = recommendation_scores.drop(labels=watched_movies, errors='ignore')

print(recommendation_scores[:10])

"""hasil diatas menampilkan top 10 rekomendasi film berdasarkan user profile yang telah dibuat

### Evaluation

Selanjutnya melihat performa metode `Collaborative Filtering`
"""

sample_titles = collab_df.columns.to_series().sample(10).tolist()

sample_titles

top_recommendations = recommendation_scores[:10].index.tolist()

# Buat penilaian manual untuk evaluasi (1 = tidak relevan, 5 = sangat relevan)
manual_relevance = {
    "Frequency": 5,
    "Meatballs": 4,
    "Unstoppable": 4,
    "Night on Earth": 2,
    "Dragonslayer": 5,
    "Fly, The": 3,
    "Walk the Line": 2,
    "Chasing Liberty": 5,
    "Pee-wee's Big Adventure": 4,
    "Shrek 2": 3,
}

# Ambil hanya film yang dinilai secara manual
evaluated_scores = recommendation_scores[manual_relevance.keys()]

# Buat DataFrame evaluasi
evaluation_df = pd.DataFrame({
    'Predicted Score': evaluated_scores,
    'Manual Relevance': pd.Series(manual_relevance)
})

# Normalisasi skor prediksi
evaluation_df['Normalized Predicted'] = evaluation_df['Predicted Score'] / evaluation_df['Predicted Score'].max()

# Hitung korelasi antara skor sistem dan penilaian manual
correlation = evaluation_df[['Normalized Predicted', 'Manual Relevance']].corr().iloc[0, 1]

# Tampilkan hasil evaluasi
print("=== Evaluation Result ===")
print(evaluation_df)
print(f"\nCorrelation between predicted and manual relevance: {correlation:.2f}")

"""Dari hasil evaluasi, metode `Collaborative Filtering` mendapatkan hasil yang kurang bagus, dimana hasil prediksinya hanya 0.17 atau 17% yang benar. Dimana hasil ini cukup rendah untuk sistem rekomendasi"""